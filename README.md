This repository has been created for my tutorial on how to run LLMs locally with Ollama in a single Docker compose project. Go check it out [here](https://doge0420.github.io/blog/deepseek/) !